{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOtiztXAKc/ciSlIkJK3w0N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HoraceTheOgre/a-PyTorch-Tutorial-to-Image-Captioning/blob/master/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVbuZOOcvDEy",
        "outputId": "529e4fe0-5622-4cf5-be61-7787c2ec1109"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'a-PyTorch-Tutorial-to-Image-Captioning'...\n",
            "remote: Enumerating objects: 272, done.\u001b[K\n",
            "remote: Total 272 (delta 0), reused 0 (delta 0), pack-reused 272 (from 1)\u001b[K\n",
            "Receiving objects: 100% (272/272), 12.89 MiB | 20.06 MiB/s, done.\n",
            "Resolving deltas: 100% (146/146), done.\n",
            "/content/a-PyTorch-Tutorial-to-Image-Captioning\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.12/dist-packages (2.0.10)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (0.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (1.16.3)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2.37.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2025.10.16)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (0.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "--2025-11-29 17:50:01--  http://images.cocodataset.org/zips/train2014.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 3.5.29.214, 16.15.177.51, 16.15.202.0, ...\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|3.5.29.214|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13510573713 (13G) [application/zip]\n",
            "Saving to: ‘train2014.zip’\n",
            "\n",
            "train2014.zip       100%[===================>]  12.58G  71.0MB/s    in 2m 58s  \n",
            "\n",
            "2025-11-29 17:53:00 (72.3 MB/s) - ‘train2014.zip’ saved [13510573713/13510573713]\n",
            "\n",
            "--2025-11-29 17:55:35--  http://images.cocodataset.org/zips/val2014.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 3.5.25.154, 16.15.179.193, 16.15.188.62, ...\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|3.5.25.154|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6645013297 (6.2G) [application/zip]\n",
            "Saving to: ‘val2014.zip’\n",
            "\n",
            "val2014.zip         100%[===================>]   6.19G  69.4MB/s    in 88s     \n",
            "\n",
            "2025-11-29 17:57:03 (72.0 MB/s) - ‘val2014.zip’ saved [6645013297/6645013297]\n",
            "\n",
            "--2025-11-29 17:58:20--  http://images.cocodataset.org/annotations/annotations_trainval2014.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 3.5.12.168, 52.217.140.217, 52.216.57.209, ...\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|3.5.12.168|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 252872794 (241M) [application/zip]\n",
            "Saving to: ‘annotations_trainval2014.zip’\n",
            "\n",
            "annotations_trainva 100%[===================>] 241.16M  94.5MB/s    in 2.6s    \n",
            "\n",
            "2025-11-29 17:58:23 (94.5 MB/s) - ‘annotations_trainval2014.zip’ saved [252872794/252872794]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Clone your repository\n",
        "!git clone https://github.com/HoraceTheOgre/a-PyTorch-Tutorial-to-Image-Captioning.git\n",
        "\n",
        "# Change the working directory\n",
        "%cd a-PyTorch-Tutorial-to-Image-Captioning/\n",
        "\n",
        "# Install the required packages from your README\n",
        "!pip install torch torchvision tqdm numpy Pillow pycocotools scikit-image\n",
        "\n",
        "# Download and unzip the COCO 2014 train/val images and annotations\n",
        "!wget http://images.cocodataset.org/zips/train2014.zip\n",
        "!unzip -q train2014.zip\n",
        "!rm train2014.zip\n",
        "\n",
        "!wget http://images.cocodataset.org/zips/val2014.zip\n",
        "!unzip -q val2014.zip\n",
        "!rm val2014.zip\n",
        "\n",
        "!wget http://images.cocodataset.org/annotations/annotations_trainval2014.zip\n",
        "!unzip -q annotations_trainval2014.zip\n",
        "!rm annotations_trainval2014.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Download the caption datasets zip file from the Stanford server\n",
        "!wget http://cs.stanford.edu/people/karpathy/deepimagesent/caption_datasets.zip\n",
        "\n",
        "# Unzip the file - this will extract 'dataset_coco.json'\n",
        "!unzip -q caption_datasets.zip\n",
        "\n",
        "# Move the JSON file into the 'annotations' directory where the script expects it\n",
        "!mv dataset_coco.json ./annotations/\n",
        "\n",
        "# The previous patch on utils.py is removed as the path is an argument, not hardcoded in utils.py\n",
        "# The problematic path originates from create_input_files.py\n",
        "\n",
        "print(\"Successfully downloaded and moved 'dataset_coco.json'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8CUReBsxnuS",
        "outputId": "a17a2cf6-9c0c-44c5-f6f0-2d25b316ab1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-29 18:01:01--  http://cs.stanford.edu/people/karpathy/deepimagesent/caption_datasets.zip\n",
            "Resolving cs.stanford.edu (cs.stanford.edu)... 171.64.64.64\n",
            "Connecting to cs.stanford.edu (cs.stanford.edu)|171.64.64.64|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://cs.stanford.edu/people/karpathy/deepimagesent/caption_datasets.zip [following]\n",
            "--2025-11-29 18:01:02--  https://cs.stanford.edu/people/karpathy/deepimagesent/caption_datasets.zip\n",
            "Connecting to cs.stanford.edu (cs.stanford.edu)|171.64.64.64|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 36745453 (35M) [application/zip]\n",
            "Saving to: ‘caption_datasets.zip’\n",
            "\n",
            "caption_datasets.zi 100%[===================>]  35.04M  12.2MB/s    in 2.9s    \n",
            "\n",
            "2025-11-29 18:01:05 (12.2 MB/s) - ‘caption_datasets.zip’ saved [36745453/36745453]\n",
            "\n",
            "Successfully downloaded and moved 'dataset_coco.json'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix the import error in utils.py by replacing deprecated scipy.misc imports\n",
        "!sed -i 's/from scipy.misc import imread, imresize/from imageio import imread\\nfrom skimage.transform import resize/g' utils.py\n",
        "# Replace imresize calls with resize\n",
        "!sed -i 's/imresize(/resize(/g' utils.py\n",
        "\n",
        "print(\"Successfully patched utils.py\")\n",
        "print(\"\\n--- Content of utils.py after patching ---\")\n",
        "# Display relevant lines to verify changes\n",
        "!grep -nE \"imread|imresize|resize|scipy.misc|imageio|skimage.transform\" utils.py | head -n 10\n",
        "!tail -n +110 utils.py | head -n 20 # Check around line 120"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4RvTOeVx3yi",
        "outputId": "ab5f4f49-7eb5-4343-b81e-506e1e4155b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully patched utils.py\n",
            "\n",
            "--- Content of utils.py after patching ---\n",
            "6:from imageio import imread\n",
            "7:from skimage.transform import resize\n",
            "116:                img = imread(impaths[i])\n",
            "120:                img = resize(img, (256, 256))\n",
            "                    captions = sample(imcaps[i], k=captions_per_image)\n",
            "\n",
            "                # Sanity check\n",
            "                assert len(captions) == captions_per_image\n",
            "\n",
            "                # Read images\n",
            "                img = imread(impaths[i])\n",
            "                if len(img.shape) == 2:\n",
            "                    img = img[:, :, np.newaxis]\n",
            "                    img = np.concatenate([img, img, img], axis=2)\n",
            "                img = resize(img, (256, 256))\n",
            "                img = img.transpose(2, 0, 1)\n",
            "                assert img.shape == (3, 256, 256)\n",
            "                assert np.max(img) <= 255\n",
            "\n",
            "                # Save image to HDF5 file\n",
            "                images[i] = img\n",
            "\n",
            "                for j, c in enumerate(captions):\n",
            "                    # Encode captions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!rm -f TRAIN_IMAGES.hdf5 VAL_IMAGES.hdf5 WORDMAP.json # Clean up existing output files\n",
        "\n",
        "# Fix the nested h5py.Fil  e call in utils.py\n",
        "!sed -i \"s|with h5py.File(h5py.File(\\(.*\\), 'a'), 'w') as h:|with h5py.File(\\\\1, 'w') as h:|g\" utils.py\n",
        "\n",
        "!sed -i \"s|karpathy_json_path='../caption data/dataset_coco.json'|karpathy_json_path='./annotations/dataset_coco.json'|g\" create_input_files.py\n",
        "!sed -i \"s|image_folder='/media/ssd/caption data/'|image_folder='./'|g\" create_input_files.py\n",
        "!sed -i \"s|output_folder='/media/ssd/caption data/'|output_folder='./'|g\" create_input_files.py\n",
        "\n",
        "!python create_input_files.py --dataset 'coco' \\\n",
        "                             --karpathy_json_path './annotations/dataset_coco.json' \\\n",
        "                             --image_folder './' \\\n",
        "                             --captions_per_image 5 \\\n",
        "                             --min_word_freq 5 \\\n",
        "                             --output_folder './' \\\n",
        "                             --max_len 50"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNXyPmUCx5wH",
        "outputId": "62262b2b-d17f-4181-81d5-3c14a5934e7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Reading TRAIN images and captions, storing to file...\n",
            "\n",
            "100% 113287/113287 [1:38:27<00:00, 19.18it/s]\n",
            "\n",
            "Reading VAL images and captions, storing to file...\n",
            "\n",
            "100% 5000/5000 [05:25<00:00, 15.38it/s]\n",
            "\n",
            "Reading TEST images and captions, storing to file...\n",
            "\n",
            "100% 5000/5000 [05:35<00:00, 14.90it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix the global 'data_folder' variable in train.py to point to the current directory.\n",
        "!sed -i \"s|data_folder = '/media/ssd/caption data'|data_folder = './'|g\" train.py\n",
        "\n",
        "# Verify the change in train.py by grepping the relevant line.\n",
        "print(\"-- Verification of 'data_folder' variable in train.py after patching --\")\n",
        "!grep \"data_folder =\" train.py\n",
        "\n",
        "# Fix for pack_padded_sequence in train.py (applied twice due to original script structure)\n",
        "!sed -i \"s|scores, _ = pack_padded_sequence(scores, decode_lengths, batch_first=True)|scores = pack_padded_sequence(scores, decode_lengths, batch_first=True)[0]|g\" train.py\n",
        "!sed -i \"s|targets, _ = pack_padded_sequence(targets, decode_lengths, batch_first=True)|targets = pack_padded_sequence(targets, decode_lengths, batch_first=True)[0]|g\" train.py\n",
        "\n",
        "# Fix the SyntaxWarning in datasets.py by changing 'is' to '==' for string comparison\n",
        "!sed -i \"s|if self.split is 'TRAIN':|if self.split == 'TRAIN':|g\" datasets.py\n",
        "!sed -i \"s|if self.split is 'VAL':|if self.split == 'VAL':|g\" datasets.py\n",
        "!sed -i \"s|if self.split is 'TEST':|if self.split == 'TEST':|g\" datasets.py\n",
        "\n",
        "# Run train.py again. With the corrected data_folder, it should now find the files.\n",
        "!python train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6p4SdzyLXc_",
        "outputId": "c54f3f6d-b0fc-489e-9d12-24ef7ef5b50c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Verification of 'data_folder' variable in train.py after patching --\n",
            "data_folder = './'  # folder with data files saved by create_input_files.py\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n",
            "100% 171M/171M [00:02<00:00, 67.9MB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "Epoch: [0][0/17702]\tBatch Time 42.505 (42.505)\tData Load Time 0.629 (0.629)\tLoss 10.0322 (10.0322)\tTop-5 Accuracy 0.000 (0.000)\n"
          ]
        }
      ]
    }
  ]
}